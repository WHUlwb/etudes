{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian linear regression\n",
    "\n",
    "If we infer the parameters of a linear regression model \n",
    "\n",
    "\\begin{align}\n",
    "\\mathbf{y} \\sim p(\\mathbf{y} \\mid (\\mathbf{X} ,\\boldsymbol \\beta, \\sigma^2 )  = \\mathcal{N}(\\mathbf{X} \\boldsymbol \\beta, \\sigma^2 \\mathbf{I}_n),\n",
    "\\end{align}\n",
    "\n",
    "where $y$ is a $n$-dimensional vector of (centered) Gaussian responses, $X$ is a $(n \\times p)$-dimensional design matrix and $\\beta$ is a vector of coefficients of appropriate size, we usually compute the MLE $\\hat{\\beta}$ as *best* solution of the problem.\n",
    "\n",
    "In a Bayesian context, where we are (I would generally argue) primarily interested in *analysis of beliefs*, instead of establishing *frequentist guarantees*, we introduce prior information to the model (I took the term *anaysis of beliefs* from Larry Wasserman, I think).\n",
    "\n",
    "As a refresher, the maximum likelihood estimate would be computed as:\n",
    "\n",
    "\\begin{align}\n",
    "\\max_{\\boldsymbol \\beta, \\sigma^2} \\mathcal{L}(\\boldsymbol \\beta, \\sigma^2) = & \\max_{\\boldsymbol \\beta, \\sigma^2} p(\\mathbf{y} \\mid \\mathbf{X}, \\boldsymbol \\beta, \\sigma^2),\\\\\n",
    " =& \\max_{\\boldsymbol \\beta, \\sigma^2} \\prod_i^n p(y_i \\mid \\mathbf{x}_i, \\boldsymbol \\beta, \\sigma^2).\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normal-Inverse Gamma Prior\n",
    "\n",
    "For a linear regression model, this would mean to put a prior distribution on the coeffients $\\beta$ and the variance $\\sigma^2$. \n",
    "\n",
    "Fere, for the coefficients we will assume a Gaussian prior (as it is conjugate to a Gaussian likelihood for our responses $y$) with mean $0$ and variance $\\sigma^2 \\mathbf{I}_p$. For $\\sigma^2$ we will use an inverse Gamma prior with hyperparameters $a$ and $b$.\n",
    "\n",
    "\\begin{align}\n",
    " \\boldsymbol \\beta  &\\sim \\mathcal{N}(\\mathbf{0}, \\sigma^2 \\mathbf{I}),\\\\\n",
    " \\sigma^2 &\\sim \\mathcal{IG}(a, b).\\\\\n",
    "\\end{align}\n",
    "\n",
    "Other choices of priors are of course also fine. For demonstration this will do, though. I refer to Gelman's *Bayesian Data Analysis* for more information.\n",
    "\n",
    "The joint prior distribution is given by a rather tedious form:\n",
    "\n",
    "\\begin{align}\n",
    " \\beta, \\sigma^2 &\\sim \\mathcal{NIG}(\\mathbf{0}, \\mathbf{I}, a, b),\\\\\n",
    " p(\\beta, \\sigma^2) &= p(\\beta \\mid \\sigma^2) \\ p(\\sigma^2) \\\\\n",
    " &= \\frac{1}{ (2\\pi\\sigma^2)^{\\frac{p}{2}}} \\exp\\left(  -\\frac{1}{2\\sigma^2}    \\boldsymbol \\beta^T \\boldsymbol \\beta \\right) \\frac{b^a}{\\Gamma(a)} \\frac{1}{(\\sigma^2)^{a+1}} \\exp\\left(  -\\frac{b}{\\sigma^2} \\right), \\\\\n",
    " &\\propto \\frac{1}{(\\sigma^2)^{\\frac{p}{2} + a + 1 }} \\exp \\left(  -\\frac{1}{2\\sigma^2} \\boldsymbol \\beta^T \\boldsymbol \\beta  -\\frac{b}{\\sigma^2}\\right)\n",
    "\\end{align}\n",
    "\n",
    "In the alst part we removed every factor that does not depend on the variables $\\boldsymbol \\beta$ and $\\sigma^2$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normal-Inverse Gamma Posterior \n",
    "\n",
    "The posterior in a Bayesian model is proportional to the likelihood times the prior. So in our case:\n",
    "\n",
    "\\begin{align}\n",
    "  \\text{posterior} &\\propto \\text{likelihood} \\times \\text{prior},\\\\\n",
    "  p(\\beta, \\sigma^2 \\mid \\mathbf{X}, \\mathbf{y}) \\propto \\; &  p(\\mathbf{y} \\mid \\mathbf{X}, \\boldsymbol \\beta, \\sigma^2) \\ p(\\boldsymbol \\beta , \\sigma^2),\\\\\n",
    "  p(\\beta, \\sigma^2 \\mid X, y) \\propto \\; & \\frac{1}{(\\sigma^2)^{\\frac{n}{2}}} \\exp \\left( -\\frac{1}{2\\sigma^2} (\\mathbf{y} - \\mathbf{X} \\boldsymbol \\beta)^T(\\mathbf{y} - \\mathbf{X} \\boldsymbol \\beta)  \\right)\\\\\n",
    " & \\; \\frac{1}{(\\sigma^2)^{\\frac{p}{2} + a + 1 }} \\exp \\left(  -\\frac{1}{2\\sigma^2} \\boldsymbol \\beta^T \\boldsymbol \\beta  -\\frac{b}{\\sigma^2}\\right),\\\\\n",
    " = \\; & \\frac{1}{(\\sigma^2)^{\\frac{n}{2} + \\frac{p}{2} + a + 1 }} \\exp \\left( -\\frac{1}{2\\sigma^2}  (\\mathbf{y} - \\mathbf{X} \\boldsymbol \\beta)^T(\\mathbf{y} - \\mathbf{X} \\boldsymbol \\beta)  -\\frac{1}{2\\sigma^2} \\boldsymbol \\beta^T \\boldsymbol \\beta  -\\frac{b}{\\sigma^2}  \\right)\n",
    "\\end{align}\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(123)\n",
    "from scipy.stats import beta\n",
    "\n",
    "def generate_dataset(num_points, true_k, dim=2, verbose=False):\n",
    "    true_z = [i % true_k for i in range(num_points)]\n",
    "    if False:\n",
    "        probs_per_cluster = np.random.rand(dim, true_k)\n",
    "    else:\n",
    "        probs_per_cluster = beta.rvs(0.5, 0.5, size=(true_k, dim))    \n",
    "\n",
    "    probs = probs_per_cluster[true_z, :]\n",
    "    data = (probs > np.random.rand(num_points, dim)).astype(np.float32)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = 5\n",
    "true_k = 3\n",
    "num_points = 100\n",
    "data = generate_dataset(100, 3, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 5)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import copy\n",
    "\n",
    "\n",
    "class DPM:\n",
    "    def __init__(self, initial_k, alpha, prior, data, z):\n",
    "       \n",
    "        self.num_clusters = initial_k\n",
    "        self.num_samples, self.dim = data.shape\n",
    "        self.alpha = alpha\n",
    "        self.copy_of_prior = prior  # when initializing a new cluster, we copy this prior to start from\n",
    "        self.data = data\n",
    "        self.z = z\n",
    "        self.N_k = [0]*initial_k  # Number of points in cluster k, like N_k in Murphy eq25.35 pg 888\n",
    "\n",
    "        self.cluster_distros = []\n",
    "        # Initialize the priors on the mixture components\n",
    "        for _ in range(initial_k):\n",
    "            self.cluster_distros.append(copy.deepcopy(prior))\n",
    "\n",
    "        self.include_points(data, z)\n",
    "\n",
    "    def include_points(self, data, z):\n",
    "        for i, x in enumerate(data):\n",
    "            k = z[i]\n",
    "            self.cluster_distros[k].additem(x)\n",
    "            self.N_k[k] += 1\n",
    "        self.num_samples = sum(self.N_k)\n",
    "\n",
    "    def step(self):\n",
    "        for i, xx in enumerate(self.data):\n",
    "            # -- 1 --\n",
    "            k_old = self.z[i]\n",
    "            self.N_k[k_old] -= 1\n",
    "            self.cluster_distros[k_old].delitem(xx)\n",
    "            self.remove_cluster_if_empty(k_old)\n",
    "            pp = self.N_k.copy()\n",
    "            pp.append(self.alpha)\n",
    "            pp = np.log(np.array(pp))\n",
    "            for k in range(self.num_clusters+1):\n",
    "                pp[k] += self.logpredictive(k, xx)\n",
    "            pp = np.exp(pp-np.max(pp))  # Subtract max to avoid numerical errors\n",
    "            pp /= np.sum(pp)\n",
    "\n",
    "            uu = np.random.rand()\n",
    "            k_new = int(np.sum(uu > np.cumsum(pp)))\n",
    "\n",
    "            # -- 3 --\n",
    "            self.add_cluster_maybe(k_new)\n",
    "\n",
    "            self.z[i] = k_new\n",
    "            self.N_k[k_new] += 1\n",
    "            self.cluster_distros[k_new].additem(xx)\n",
    "\n",
    "    def add_cluster_maybe(self, k_new):\n",
    "        if k_new == self.num_clusters:\n",
    "            self.num_clusters += 1\n",
    "            self.N_k.append(0)\n",
    "            self.cluster_distros.append(copy.deepcopy(self.copy_of_prior))\n",
    "\n",
    "    def logpredictive(self, k, xx):\n",
    "        if not k == self.num_clusters:\n",
    "            q = self.cluster_distros[k]\n",
    "        else:\n",
    "            q = copy.deepcopy(self.copy_of_prior)\n",
    "        return q.logpred(xx)\n",
    "\n",
    "    def remove_cluster_if_empty(self, k):\n",
    "        if self.N_k[k] == 0:\n",
    "            self.num_clusters -= 1\n",
    "            self.cluster_distros.pop(k)\n",
    "            self.N_k.pop(k)\n",
    "            self.z[np.argwhere(self.z > k)] -= 1\n",
    "\n",
    "    def print_probs(self):\n",
    "        print('The MAP assignments of the clusters that we sampled')\n",
    "        for i, k in enumerate(np.argsort(self.N_k)[::-1]):\n",
    "            q = self.cluster_distros[k]\n",
    "            map_assignment = q.get_posterior_multinoulli('map')\n",
    "            print('Cluster %3i with %5i data and MAP %s' %\n",
    "                  (k, q.num, ' - '.join(['%5.2f' % prob for prob in map_assignment])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import beta\n",
    "\n",
    "\n",
    "class Multinoulli:\n",
    "    def __init__(self, dim, beta, gamma):\n",
    "        self.dim = dim\n",
    "        self.num = 0  # number of points currently assigned to the cluster\n",
    "        self.counts = np.zeros(shape=(dim,))\n",
    "        self.beta = beta\n",
    "        self.gamma = gamma\n",
    "\n",
    "    def logpred(self, xx):\n",
    "        result = 0\n",
    "\n",
    "        for i, xd in enumerate(xx):\n",
    "            if xd > 0:\n",
    "                result += np.log(self.beta + self.counts[i])\n",
    "            else:\n",
    "                result += np.log(self.gamma + (self.num - self.counts[i]))\n",
    "\n",
    "        result -= self.dim*np.log(self.beta + self.gamma + self.num)\n",
    "        return result\n",
    "\n",
    "    def delitem(self, xx):\n",
    "        self.num -= 1\n",
    "        self.counts -= xx  # assumes xx in {0,1}\n",
    "\n",
    "    def additem(self, xx):\n",
    "        self.num += 1\n",
    "        self.counts += xx\n",
    "\n",
    "    def get_posterior_multinoulli(self, mode='sample'):\n",
    "        assert mode in ['map', 'sample'], \"expected mode 'map' or 'sample'\"\n",
    "        if mode == 'sample':\n",
    "            probs = beta.rvs(self.counts + self.beta, self.num - self.counts + self.gamma)\n",
    "        else:\n",
    "            probs = (self.beta + self.counts)/(self.beta + self.gamma + self.num)\n",
    "        return probs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "q0 = Multinoulli(dim=dim, beta=1, gamma=1)\n",
    "\n",
    "alpha = 5\n",
    "initial_guess_K = 1\n",
    "z = np.random.randint(0, initial_guess_K, (num_points,))\n",
    "\n",
    "dpm = DPM(initial_guess_K, alpha, q0, data, z)\n",
    "\n",
    "numstep = 100\n",
    "\n",
    "burn_in = 10\n",
    "sample_every = 3\n",
    "num_clusters = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average number of clusters  11.3 \n",
      "\n",
      "The MAP assignments of the clusters that we sampled\n",
      "Cluster   0 with    67 data and MAP  0.12 -  0.72 -  0.94 -  0.46 -  0.07\n",
      "Cluster   1 with    13 data and MAP  0.80 -  0.07 -  0.73 -  0.07 -  0.40\n",
      "Cluster   2 with     8 data and MAP  0.60 -  0.60 -  0.30 -  0.10 -  0.50\n",
      "Cluster   5 with     6 data and MAP  0.75 -  0.12 -  0.12 -  0.50 -  0.25\n",
      "Cluster   7 with     2 data and MAP  0.25 -  0.50 -  0.75 -  0.75 -  0.50\n",
      "Cluster   4 with     2 data and MAP  0.25 -  0.25 -  0.75 -  0.50 -  0.50\n",
      "Cluster   6 with     1 data and MAP  0.33 -  0.33 -  0.33 -  0.67 -  0.33\n",
      "Cluster   3 with     1 data and MAP  0.67 -  0.67 -  0.33 -  0.33 -  0.33\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "for step in range(1, numstep):\n",
    "    dpm.step()\n",
    "    if step > burn_in:\n",
    "        if step % sample_every == 0:\n",
    "            num_clusters.append(len(dpm.N_k))\n",
    "\n",
    "print('Average number of clusters %5.1f \\n' % (np.mean(num_clusters)))\n",
    "print(dpm.print_probs())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

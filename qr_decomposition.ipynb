{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QR-decomposition\n",
    "\n",
    "Here we implement a QR-decomposition which is amongst other things used in linear regression for **numerical stability**.\n",
    "We apply our QR-decomposition for modelling a linear association and compare it to the analytical solution from `statsmodels` (which I recommend over `sklearn` as it computes t-values and condidence intervals)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The QR-decomposition can be used on any $(n \\times p)$-dimensional **full rank** matrix $\\mathbf{X}$ as:\n",
    "\n",
    "\\begin{equation}\n",
    "\\mathbf{X} = \\mathbf{QR},\n",
    "\\end{equation}\n",
    "\n",
    "where $\\mathbf{Q} \\in \\mathbb{R}^{n \\times n}$ and $\\mathbf{R} \\in \\mathbb{R}^{n \\times p}$. Most importantly: $\\mathbf{Q}^T \\mathbf{Q} = \\mathbf{I}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's quickly recap linear regression. We model a linear dependency $f: \\mathcal{X} \\rightarrow \\mathcal{Y}$ as:\n",
    "\n",
    "\\begin{align*}\n",
    "\\mathbf{y} \\sim \\mathcal{N}(\\mathbf{X}\\boldsymbol \\beta, \\boldsymbol \\sigma^2),\n",
    "\\end{align*}\n",
    "\n",
    "which we solve using maximum likelihood. For Gaussian responses this is identical to solving:\n",
    "\n",
    "\\begin{align*}\n",
    "\\min_{\\boldsymbol \\beta} ||\\mathbf{y}  - \\mathbf{X}\\boldsymbol \\beta||^2_2.\n",
    "\\end{align*}\n",
    "\n",
    "Taking the derivative and setting it to $0$ yields:\n",
    "\\begin{align*}\n",
    "\\mathbf{X}^T\\mathbf{X} \\boldsymbol \\beta &= \\mathbf{X}^T \\mathbf{y}\\\\\n",
    "(\\mathbf{QR})^T\\mathbf{QR} \\boldsymbol \\beta &=  (\\mathbf{QR})^T \\mathbf{y} \\\\\n",
    "\\mathbf{R}^T\\mathbf{Q}^T\\mathbf{QR} \\boldsymbol \\beta &=  (\\mathbf{QR})^T \\mathbf{y} \\\\\n",
    "\\mathbf{R}^T \\mathbf{R} \\boldsymbol \\beta &=  \\mathbf{R}^T \\mathbf{Q}^T \\mathbf{y} \\\\\n",
    "\\mathbf{R} \\boldsymbol \\beta &=  \\mathbf{Q}^T \\mathbf{y}.\n",
    "\\end{align*}\n",
    "\n",
    "The last part can be easily solved. Since $\\mathbf{R}$ is upper triangular we can use `scipy`'s [solve_triangular](https://docs.scipy.org/doc/scipy/reference/generated/scipy.linalg.solve_triangular.html) function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having set the theoretical groundwork, let's implement this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/simondi/anaconda3/envs/py36/lib/python3.6/site-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy import linalg\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we create some artificial data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "P = 5\n",
    "np.random.seed(23)\n",
    "beta = np.random.normal(size=P)\n",
    "x = np.random.normal(size=(100, P))\n",
    "y =  np.dot(x, beta) + np.random.normal(size=(100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we implement the QR-decomposition unsing the Householder triangularization. See *Numerical Recipes* by William Press *et al* and http://www.seas.ucla.edu/~vandenbe/133A/lectures/qr.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def House(a):\n",
    "    I = np.eye(a.shape[0])\n",
    "    v = a / (a[0] + np.copysign(np.linalg.norm(a), a[0]))\n",
    "    v[0] = 1\n",
    "    H = I - (2 / np.dot(v, v)) * np.dot(v[:, None], v[None, :])\n",
    "    return H\n",
    "\n",
    "def qr(A):\n",
    "    m, n = A.shape\n",
    "    Q = np.eye(m)\n",
    "    for i in range(n - (m == n)):\n",
    "        H = np.eye(m)\n",
    "        H[i:, i:] = House(A[i:, i])\n",
    "        Q = np.dot(Q, H)\n",
    "        A = np.dot(H, A)\n",
    "    return Q, A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The QR-decomposition creates two matrices ($Q$ and $R$). We use it with the design matrix $\\mathbf{X}$ as described above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape Q: (100, 100)\n",
      "Shape R: (100, 5)\n"
     ]
    }
   ],
   "source": [
    "Q, R = qr(x)\n",
    "print(\"Shape Q:\", Q.shape)\n",
    "print(\"Shape R:\", R.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having estimated $Q$ and $R$, we can estimate the coefficients of the linear model. However, first we need to reduce the matrices to fit the dimensions of our data.\n",
    "\n",
    "$R$ is upper triangular, i.e. everything below the diagonal should be zero:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 8.88330684e+00, -2.92345419e-01,  4.44391490e-01],\n",
       "       [-1.54368023e-17, -1.05501105e+01, -6.54961705e-01],\n",
       "       [ 8.28227958e-17, -1.49933382e-16, -9.68056219e+00],\n",
       "       [ 1.24903834e-16,  3.35921668e-16,  4.76961851e-16],\n",
       "       [ 2.40806889e-16, -1.21141555e-16, -8.41804989e-17]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R[:5,:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For $Q$ we just take the first $P$ columns to fit the dimensions of\n",
    "\\begin{equation}\n",
    "\\mathbf{R} \\boldsymbol \\beta =  \\mathbf{Q}^T \\mathbf{y}.\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "R = R[:P, :P]\n",
    "Q = Q[:, :P]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next line solves the system and linear equations and by that estimates the coefficients $\\boldsymbol \\beta$ of the linear regression model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.73876796,  0.00352937, -0.68071947,  1.06087307,  0.85881879])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beta_qr = linalg.solve_triangular(R, np.dot(Q.T, y))\n",
    "beta_qr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what the `statsmodel` implementation gives us:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit = sm.OLS(y, x).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.73876796,  0.00352937, -0.68071947,  1.06087307,  0.85881879])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit.params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sweet, these are the exact same results. So our prototype implementation of the QR-decomposition apparently worked.\n",
    "Using a well-maintained package is of course still preferable to our implementation. \n",
    "\n",
    "`statsmodels`'s summary function is almost the same as in modelling with `R`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.737</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.723</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   53.13</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sat, 21 Apr 2018</td> <th>  Prob (F-statistic):</th> <td>4.96e-26</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>20:20:55</td>     <th>  Log-Likelihood:    </th> <td> -139.27</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   100</td>      <th>  AIC:               </th> <td>   288.5</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    95</td>      <th>  BIC:               </th> <td>   301.6</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     5</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "   <td></td>     <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th> <td>    0.7388</td> <td>    0.113</td> <td>    6.548</td> <td> 0.000</td> <td>    0.515</td> <td>    0.963</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th> <td>    0.0035</td> <td>    0.095</td> <td>    0.037</td> <td> 0.970</td> <td>   -0.185</td> <td>    0.192</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th> <td>   -0.6807</td> <td>    0.104</td> <td>   -6.547</td> <td> 0.000</td> <td>   -0.887</td> <td>   -0.474</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th> <td>    1.0609</td> <td>    0.104</td> <td>   10.169</td> <td> 0.000</td> <td>    0.854</td> <td>    1.268</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5</th> <td>    0.8588</td> <td>    0.109</td> <td>    7.911</td> <td> 0.000</td> <td>    0.643</td> <td>    1.074</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 0.065</td> <th>  Durbin-Watson:     </th> <td>   1.959</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.968</td> <th>  Jarque-Bera (JB):  </th> <td>   0.109</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.057</td> <th>  Prob(JB):          </th> <td>   0.947</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.886</td> <th>  Cond. No.          </th> <td>    1.27</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.737\n",
       "Model:                            OLS   Adj. R-squared:                  0.723\n",
       "Method:                 Least Squares   F-statistic:                     53.13\n",
       "Date:                Sat, 21 Apr 2018   Prob (F-statistic):           4.96e-26\n",
       "Time:                        20:20:55   Log-Likelihood:                -139.27\n",
       "No. Observations:                 100   AIC:                             288.5\n",
       "Df Residuals:                      95   BIC:                             301.6\n",
       "Df Model:                           5                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "x1             0.7388      0.113      6.548      0.000       0.515       0.963\n",
       "x2             0.0035      0.095      0.037      0.970      -0.185       0.192\n",
       "x3            -0.6807      0.104     -6.547      0.000      -0.887      -0.474\n",
       "x4             1.0609      0.104     10.169      0.000       0.854       1.268\n",
       "x5             0.8588      0.109      7.911      0.000       0.643       1.074\n",
       "==============================================================================\n",
       "Omnibus:                        0.065   Durbin-Watson:                   1.959\n",
       "Prob(Omnibus):                  0.968   Jarque-Bera (JB):                0.109\n",
       "Skew:                           0.057   Prob(JB):                        0.947\n",
       "Kurtosis:                       2.886   Cond. No.                         1.27\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py36-test",
   "language": "python",
   "name": "py36-test"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
